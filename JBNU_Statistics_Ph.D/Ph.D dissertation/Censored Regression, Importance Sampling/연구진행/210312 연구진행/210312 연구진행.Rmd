---
title: "Importance Sampling"
author: "Hwang Seong-Yun"
date: '2021 03 12 '
output: html_document
---

## 실제 자료에 있는 변수에 대한 g(x)를 추정 후 h(x)를 적절히 선택하여 분산을 줄일 수 있는지 확인 (R의 density 함수, kde package ?)

- $E _{g} [f(X)]= \int _{} ^{} {f(x)g(x)dx= \int _{} ^{} {\frac {f(x)g(x)} {h(x)} h(x)dx=E _{h} [\frac {f(X)g(X)} {h(X)} ]=m}}$
- $V _{1} ,V _{2} ,...,V _{n} \sim h(v)$
- ${\hat{m}} = \frac {1}{n} \sum _{i=1} ^{n} \frac{f(V _{i} )g(V _{i} )} {h(V _{i} )}$
- 주어진 자료에 대한 분포가 주어지지 않은 경우에는 그 분포를 추정해야 함. (g(x)를 추정)
- 이후 추정된 분포 g(x)에 대한 특정값에서의 함수값을 구하는 것이 관건이라고 판단됨. 이 문제가 해결된다면 Importance Sampling에 대한 성능평가를 제대로 할 수 있음.

### transplant data 

- 목적 : 변수 time의 평균을 추정 (censoring은 무시)
- 분포 g(x)는 모수적인 방법으로 추정

```{r}
transplant <- read.csv("C:/Users/HSY/Desktop/transplant.csv",sep=",",header=T)
head(transplant)
```

```{r}
plot(density(transplant$time))
rug(jitter(transplant$time))
```

```{r}
hist(transplant$time,freq=FALSE)
lines(density(transplant$time))
```

```{r}
mean(transplant$time)
```

- 우선 자료를 통해서 단순추정한 time의 평균은 17.6325이다.
- 그래프를 통해 변수 time에 대한 적절한 분포를 Gamma 아니면 Weibull로 생각해볼 수 있다.

#### Gamma distribution 가정

- $X \sim Gamma(\alpha,\beta )$
- $f _{X} (x)= \frac{1} {\Gamma(\alpha)\beta^{\alpha }} x ^{\alpha -1} e ^{-\frac {x} {\beta }} ,x>0,\Gamma (\alpha )= \int _{0} ^{\infty} {x ^{\alpha -1}} e ^{-x} dx$
- $E(X)= \alpha  \beta , Var(X)= \alpha  \beta  ^{2}$

```{r}
library(fitdistrplus)
f1 <- fitdist(transplant$time, "gamma")
summary(f1)
plot(f1)
gofstat(f1)
gofstat(f1)$chisqpvalue
```

- Gamma 분포를 가정한 결과 shape 모수는 1.05898706, rate 모수는 0.06006563(scale 모수는 16.64846)로 추정되었다. 그리고 이 분포에 대한 이론적인 평균은 17.6305이다.
- 그리고 Chi-square p-value를 통해 변수 time에 대한 적절한 분포가 Gamma 분포라는 귀무가설을 기각하지 못하므로 Gamma 분포를 가정하는 것이 통계적으로 타당하다고 볼 수 있다.
- 이를 바탕으로 추정된 g(x)를 Gamma(1.05898706,16.64846)로 두고 적절한 대체분포 h(x)를 찾아보도록 한다.

```{r}
x <- seq(0,120,0.001)
g <- dgamma(x,shape=f1$estimate[1],scale=1/f1$estimate[2])
h <- dgamma(x,shape=2,scale=20)
plot(x,g,ylab="g(x) or h(x)",xlab="x",ylim=c(0,0.06),type="l",col="#228B22")
par(new=T)
plot(x,h,ylab="",xlab="x",ylim=c(0,0.06),type="l",col="#FF3030")
legend(x=20,y=0.06, c("g(x) : Gamma(1.05898706,16.64846)","h(x) : Gamma(2,20)"),lty=1,col=c("#228B22","#FF3030"))
```

- h(x)를 g(x)에 비해 오른쪽 꼬리가 더 두꺼운 분포로 선정하였다.
- h(x) : Gamma(2,20)

#### 모의실험

- 다음의 두가지 방법을 비교하기 위한 모의실험
- 1. 실제 분포인 g(x)를 통해 난수 추출
- 2. h(x)를 이용한 importance sampling을 통해 난수 추출
- 1,2의 방법을 통해 1000개의 난수를 추출하고 각각의 평균과 분산을 계산함.
- 이 과정을 1000번 반복하여 결과를 확인.

```{r}
GM <- c()
GV <- c()
GB <- c()
ISM <- c()
ISV <- c()
ISB <- c()
for (i in 1:1000) {
  gr <- rgamma(1000,shape=f1$estimate[1],scale=1/f1$estimate[2])
  GM[i] <- mean(gr)
  GV[i] <- var(gr)
  GB[i] <- abs(mean(gr)-f1$estimate[1]/f1$estimate[2])
  v <- rgamma(1000,shape=2,scale=20)
  g <- dgamma(v,shape=f1$estimate[1],scale=1/f1$estimate[2])
  h <- dgamma(v,shape=2,scale=20) 
  ISM[i] <- mean(v*g/h)
  ISV[i] <- var(v*g/h)
  ISB[i] <- abs(mean(v*g/h)-f1$estimate[1]/f1$estimate[2])
}
res1 <- data.frame(mean=c(GM,ISM),variance=c(GV,ISV),bias=c(GB,ISB),method=c(rep("Sampling",1000),rep("Importance Sampling",1000)))
```

- 평균추정결과

```{r}
library(ggplot2)
ggplot(res1,aes(x=method,y=mean,fill=method)) +
  geom_boxplot() +
  ggtitle("Estimate mean (Sampling vs Importance Sampling) / Gamma")
```

- 분산 비교

```{r}
ggplot(res1,aes(x=method,y=variance,fill=method)) +
  geom_boxplot() +
  ggtitle("Comparing variance (Sampling vs Importance Sampling) / Gamma")
```

- 편향 비교

```{r}
ggplot(res1,aes(x=method,y=bias,fill=method)) +
  geom_boxplot() +
  ggtitle("Comparing bias (Sampling vs Importance Sampling) / Gamma")
```

- 결과적으로 Importance Sampling을 적용했을 경우 분산과 편향 모두 감소함을 확인할 수 있다.
- 추가적으로 MSE, Variance, Bias^2 에 대한 추정량까지 비교하면 다음과 같다.

#### MSE, Variance, Bias^2 에 대한 추정량 비교

- ${MSE} =E[(M-M_{0} )  ^{2} ]$
- $\hat{MSE} = \frac{1} {n} \sum _{i=1} ^{n} (M_{i} -M_{0} )^{2}$
- ${Var} =E[(M-E(M))  ^{2} ]$
- $\hat{Var} = \frac{1} {n} \sum _{i=1} ^{n} [M_{i} -( \frac{1} {n} \sum _{j=1} ^{n} M_{j} )]^{2}$
- ${Bias}^{2}=(E(M)-M_{0})^{2}$
- $\hat{Bias}^{2} =[( \frac{1} {n} \sum _{j=1} ^{n} M_{j} )-M_{0} ]^{2}$
- $M$ : GM 또는 ISM을 통해 계산된 평균추정값
- $M_{0}$ : 실제 분포에 대한 이론적인 평균

```{r}
(MSE.GM <- mean((res1$mean[res1$method=="Sampling"]-f1$estimate[1]/f1$estimate[2])^2))
(MSE.ISM <- mean((res1$mean[res1$method=="Importance Sampling"]-f1$estimate[1]/f1$estimate[2])^2))
MSE.GM > MSE.ISM
(Var.GM <- mean((res1$mean[res1$method=="Sampling"]-mean(res1$mean[res1$method=="Sampling"]))^2))
(Var.ISM <- mean((res1$mean[res1$method=="Importance Sampling"]-mean(res1$mean[res1$method=="Importance Sampling"]))^2))
Var.GM > Var.ISM
(Bias2.GM <- (mean(res1$mean[res1$method=="Sampling"])-f1$estimate[1]/f1$estimate[2])^2)
(Bias2.ISM <- (mean(res1$mean[res1$method=="Importance Sampling"])-f1$estimate[1]/f1$estimate[2])^2)
Bias2.GM > Bias2.ISM
```

- 분석한 결과, Importance Sampling을 수행하였을 때 MSE, Variance, Bias^2 에 대한 추정량이 일반 Sampling의 경우와 비교했을 때 모두 줄어드는 것을 확인할 수 있다. 

#### Weibull distribution 가정

- $X \sim Weibull(\alpha,\beta )$
- $f _{X} (x)=( \frac{\alpha } {\beta } )(\frac {x} {\beta } ) ^{\alpha -1} exp(-(\frac {x} {\beta } ) ^{\alpha } ),x>0$
- $E(X)= \beta  \Gamma (1+ \frac{1} {\alpha } ),Var(X)= \beta  ^{2} [ \Gamma (1+ \frac{2} {\alpha } )- (\Gamma (1+ \frac{1} {\alpha } )) ^{2} ]$

```{r}
library(fitdistrplus)
f2 <- fitdist(transplant$time, "weibull")
summary(f2)
plot(f2)
gofstat(f2)
gofstat(f2)$chisqpvalue
```

- Weibull 분포를 가정한 결과 shape 모수는 1.051707, scale 모수는 17.979942로 추정되었다. 그리고 이 분포에 대한 이론적인 평균은 17.62394 이다.
- 그리고 Chi-square p-value를 통해 변수 time에 대한 적절한 분포가 Weibull 분포라는 귀무가설을 기각하지 못하므로 Weibull 분포를 가정하는 것이 통계적으로 타당하다고 볼 수 있다.
- 이를 바탕으로 추정된 g(x)를 Weibull(1.051707,17.979942)로 두고 적절한 대체분포 h(x)를 찾아보도록 한다.

```{r}
x <- seq(0,120,0.001)
g <- dweibull(x,shape=f2$estimate[1],scale=f2$estimate[2])
h <- dweibull(x,shape=f2$estimate[1],scale=25)
plot(x,g,ylab="g(x) or h(x)",xlab="x",ylim=c(0,0.06),type="l",col="#228B22")
par(new=T)
plot(x,h,ylab="",xlab="x",ylim=c(0,0.06),type="l",col="#FF3030")
legend(x=20,y=0.06, c("g(x) : Weibull(1.051707,17.979942)","h(x) : Weibull(1.051707,25)"),lty=1,col=c("#228B22","#FF3030"))
```

- h(x)를 g(x)에 비해 오른쪽 꼬리가 더 두꺼운 분포로 선정하였다.
- h(x) : Weibull(1.051707,25)

#### 모의실험

- 다음의 두가지 방법을 비교하기 위한 모의실험
- 1. 실제 분포인 g(x)를 통해 난수 추출
- 2. h(x)를 이용한 importance sampling을 통해 난수 추출
- 1,2의 방법을 통해 1000개의 난수를 추출하고 각각의 평균과 분산을 계산함.
- 이 과정을 1000번 반복하여 결과를 확인.

```{r}
GM <- c()
GV <- c()
GB <- c()
ISM <- c()
ISV <- c()
ISB <- c()
for (i in 1:1000) {
  gr <- rweibull(1000,shape=f2$estimate[1],scale=f2$estimate[2])
  GM[i] <- mean(gr)
  GV[i] <- var(gr)
  GB[i] <- abs(mean(gr)-f2$estimate[2]*gamma(1+1/f2$estimate[1]))
  v <- rweibull(1000,shape=f2$estimate[1],scale=25)
  g <- dweibull(v,shape=f2$estimate[1],scale=f2$estimate[2])
  h <- dweibull(v,shape=f2$estimate[1],scale=25) 
  ISM[i] <- mean(v*g/h)
  ISV[i] <- var(v*g/h)
  ISB[i] <- abs(mean(v*g/h)-f2$estimate[2]*gamma(1+1/f2$estimate[1]))
}
res2 <- data.frame(mean=c(GM,ISM),variance=c(GV,ISV),bias=c(GB,ISB),method=c(rep("Sampling",1000),rep("Importance Sampling",1000)))
```

- 평균추정결과

```{r}
library(ggplot2)
ggplot(res2,aes(x=method,y=mean,fill=method)) +
  geom_boxplot() +
  ggtitle("Estimate mean (Sampling vs Importance Sampling) / Weibull")
```

- 분산 비교

```{r}
ggplot(res2,aes(x=method,y=variance,fill=method)) +
  geom_boxplot() +
  ggtitle("Comparing variance (Sampling vs Importance Sampling) / Weibull")
```

- 편향 비교

```{r}
ggplot(res2,aes(x=method,y=bias,fill=method)) +
  geom_boxplot() +
  ggtitle("Comparing bias (Sampling vs Importance Sampling) / Weibull")
```

- 결과적으로 Importance Sampling을 적용했을 경우 분산과 편향 모두 감소함을 확인할 수 있다.
- 추가적으로 MSE, Variance, Bias^2 에 대한 추정량까지 비교하면 다음과 같다.

#### MSE, Variance, Bias^2 에 대한 추정량 비교

- ${MSE} =E[(M-M_{0} )  ^{2} ]$
- $\hat{MSE} = \frac{1} {n} \sum _{i=1} ^{n} (M_{i} -M_{0} )^{2}$
- ${Var} =E[(M-E(M))  ^{2} ]$
- $\hat{Var} = \frac{1} {n} \sum _{i=1} ^{n} [M_{i} -( \frac{1} {n} \sum _{j=1} ^{n} M_{j} )]^{2}$
- ${Bias}^{2}=(E(M)-M_{0})^{2}$
- $\hat{Bias}^{2} =[( \frac{1} {n} \sum _{j=1} ^{n} M_{j} )-M_{0} ]^{2}$
- $M$ : GM 또는 ISM을 통해 계산된 평균추정값
- $M_{0}$ : 실제 분포에 대한 이론적인 평균

```{r}
(MSE.GM <- mean((res2$mean[res2$method=="Sampling"]-f2$estimate[2]*gamma(1+1/f2$estimate[1]))^2))
(MSE.ISM <- mean((res2$mean[res2$method=="Importance Sampling"]-f2$estimate[2]*gamma(1+1/f2$estimate[1]))^2))
MSE.GM > MSE.ISM
(Var.GM <- mean((res2$mean[res2$method=="Sampling"]-mean(res2$mean[res2$method=="Sampling"]))^2))
(Var.ISM <- mean((res2$mean[res2$method=="Importance Sampling"]-mean(res2$mean[res2$method=="Importance Sampling"]))^2))
Var.GM > Var.ISM
(Bias2.GM <- (mean(res2$mean[res2$method=="Sampling"])-f2$estimate[2]*gamma(1+1/f2$estimate[1]))^2)
(Bias2.ISM <- (mean(res2$mean[res2$method=="Importance Sampling"])-f2$estimate[2]*gamma(1+1/f2$estimate[1]))^2)
Bias2.GM > Bias2.ISM
```

- 분석한 결과, Importance Sampling을 수행하였을 때 MSE, Variance, Bias^2 에 대한 추정량이 일반 Sampling의 경우와 비교했을 때 모두 줄어드는 것을 확인할 수 있다. 



### 모의실험

#### 과정 요약
- 1. 특정한 분포(e.g : Gamma(2,3))에서 난수 1000개 추출
- 2. 1에서 지정한 특정한 분포는 잊어버리고 추출한 난수를 가지고 다시 분포 g(x)를 추정(Gamma, Weibull 등등)
- 3. 추정된 분포에 대해 모수를 조절하여 적절한 대체분포 h(x)를 설정
- 4. 1000번 반복 모의실험
- 5. 결과확인

```{r}
library(fitdistrplus)
GM <- c()
GV <- c()
GB <- c()
ISM <- c()
ISV <- c()
ISB <- c()
for (i in 1:1000) {
  random <- rgamma(1000,shape=2,scale=3)
  f3 <- fitdist(random,"gamma")
  gr <- rgamma(1000,shape=f3$estimate[1],scale=1/f3$estimate[2])
  GM[i] <- mean(gr)
  GV[i] <- var(gr)
  GB[i] <- abs(mean(gr)-f3$estimate[1]/f3$estimate[2])
  v <- rgamma(1000,shape=f3$estimate[1],scale=(1/f3$estimate[2])+1)
  g <- dgamma(v,shape=f3$estimate[1],scale=1/f3$estimate[2])
  h <- dgamma(v,shape=f3$estimate[1],scale=(1/f3$estimate[2])+1) 
  ISM[i] <- mean(v*g/h)
  ISV[i] <- var(v*g/h)
  ISB[i] <- abs(mean(v*g/h)-f3$estimate[1]/f3$estimate[2])
}
res3 <- data.frame(mean=c(GM,ISM),variance=c(GV,ISV),bias=c(GB,ISB),method=c(rep("Sampling",1000),rep("Importance Sampling",1000)))
```

- 평균추정결과

```{r}
library(ggplot2)
ggplot(res3,aes(x=method,y=mean,fill=method)) +
  geom_boxplot() +
  ggtitle("Estimate mean (Sampling vs Importance Sampling)")
```

- 분산 비교

```{r}
ggplot(res3,aes(x=method,y=variance,fill=method)) +
  geom_boxplot() +
  ggtitle("Comparing variance (Sampling vs Importance Sampling)")
```

- 편향 비교

```{r}
ggplot(res3,aes(x=method,y=bias,fill=method)) +
  geom_boxplot() +
  ggtitle("Comparing bias (Sampling vs Importance Sampling)")
```

- 결과적으로 Importance Sampling을 적용했을 경우 분산과 편향 모두 감소함을 확인할 수 있다.
